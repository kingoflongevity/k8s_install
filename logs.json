{"logs":[{"id":"1767875128445162100","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nsudo kubeadm reset --force\n\n# 清理CNI配置\nsudo rm -rf /etc/cni/net.d\n\n# 重置iptables规则\nsudo iptables -F\nsudo iptables -t nat -F\nsudo iptables -t mangle -F\nsudo iptables -X\n\n# 重置ip6tables规则\nsudo ip6tables -F\nsudo ip6tables -t nat -F\nsudo ip6tables -t mangle -F\nsudo ip6tables -X\n\n# 如果使用IPVS，重置IPVS表\nif command -v ipvsadm \u0026\u003e /dev/null; then\n    sudo ipvsadm --clear\nfi\n\n# 清理kubeconfig文件\nsudo rm -rf ~/.kube\nrm -rf $HOME/.kube\n# 清理集群配置文件\nsudo rm -f /etc/kubernetes/admin.conf\nsudo rm -f /etc/kubernetes/kubelet.conf\nsudo rm -f /etc/kubernetes/controller-manager.conf\nsudo rm -f /etc/kubernetes/scheduler.conf\nsudo rm -rf /etc/kubernetes/manifests\n\n# 清理旧的etcd数据\nsudo rm -rf /var/lib/etcd\n\n# 清理旧的kubelet数据\nsudo rm -rf /var/lib/kubelet\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 20:25:29.145288  223300 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:25:29.164761  223300 cleanupnode.go:134] [reset] Failed to evaluate the \"/var/lib/kubelet\" directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory\nW0108 20:25:29.777948  223374 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:25:29+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 20:25:29.145288  223300 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\nW0108 20:25:29.164761  223300 cleanupnode.go:134] [reset] Failed to evaluate the \"/var/lib/kubelet\" directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 20:25:29.777948  223374 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:25:29+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T20:25:28.4451621+08:00","updatedAt":"2026-01-08T20:25:29.7322473+08:00"},{"id":"1767875127767438100","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T20:25:27.7674381+08:00","updatedAt":"2026-01-08T20:25:28.4342368+08:00"},{"id":"1767874995229169100","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nsudo kubeadm reset --force\n\n# 清理CNI配置\nsudo rm -rf /etc/cni/net.d\n\n# 重置iptables规则\nsudo iptables -F\nsudo iptables -t nat -F\nsudo iptables -t mangle -F\nsudo iptables -X\n\n# 重置ip6tables规则\nsudo ip6tables -F\nsudo ip6tables -t nat -F\nsudo ip6tables -t mangle -F\nsudo ip6tables -X\n\n# 如果使用IPVS，重置IPVS表\nif command -v ipvsadm \u0026\u003e /dev/null; then\n    sudo ipvsadm --clear\nfi\n\n# 清理kubeconfig文件\nsudo rm -rf ~/.kube\nrm -rf $HOME/.kube\n# 清理集群配置文件\nsudo rm -f /etc/kubernetes/admin.conf\nsudo rm -f /etc/kubernetes/kubelet.conf\nsudo rm -f /etc/kubernetes/controller-manager.conf\nsudo rm -f /etc/kubernetes/scheduler.conf\nsudo rm -rf /etc/kubernetes/manifests\n\n# 清理旧的etcd数据\nsudo rm -rf /var/lib/etcd\n\n# 清理旧的kubelet数据\nsudo rm -rf /var/lib/kubelet\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 20:23:15.930600  222262 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:23:15.948990  222262 cleanupnode.go:134] [reset] Failed to evaluate the \"/var/lib/kubelet\" directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory\nW0108 20:23:16.596126  222337 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:23:16+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\nW0108 20:23:15.930600  222262 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:23:15.948990  222262 cleanupnode.go:134] [reset] Failed to evaluate the \"/var/lib/kubelet\" directory. Skipping its unmount and cleanup: lstat /var/lib/kubelet: no such file or directory\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 20:23:16.596126  222337 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:23:16+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T20:23:15.2291691+08:00","updatedAt":"2026-01-08T20:23:16.539526+08:00"},{"id":"1767874994557002600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T20:23:14.5570026+08:00","updatedAt":"2026-01-08T20:23:15.2078209+08:00"},{"id":"1767874976975757300","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nsudo kubeadm reset --force\n\n# 清理CNI配置\nsudo rm -rf /etc/cni/net.d\n\n# 重置iptables规则\nsudo iptables -F\nsudo iptables -t nat -F\nsudo iptables -t mangle -F\nsudo iptables -X\n\n# 重置ip6tables规则\nsudo ip6tables -F\nsudo ip6tables -t nat -F\nsudo ip6tables -t mangle -F\nsudo ip6tables -X\n\n# 如果使用IPVS，重置IPVS表\nif command -v ipvsadm \u0026\u003e /dev/null; then\n    sudo ipvsadm --clear\nfi\n\n# 清理kubeconfig文件\nsudo rm -rf ~/.kube\nrm -rf $HOME/.kube\n# 清理集群配置文件\nsudo rm -f /etc/kubernetes/admin.conf\nsudo rm -f /etc/kubernetes/kubelet.conf\nsudo rm -f /etc/kubernetes/controller-manager.conf\nsudo rm -f /etc/kubernetes/scheduler.conf\nsudo rm -rf /etc/kubernetes/manifests\n\n# 清理旧的etcd数据\nsudo rm -rf /var/lib/etcd\n\n# 清理旧的kubelet数据\nsudo rm -rf /var/lib/kubelet\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 20:22:57.678598  221900 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:22:58.782793  221981 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:22:58+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 20:22:57.678598  221900 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 20:22:58.782793  221981 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CRI]: container runtime is not running: output: time=\"2026-01-08T20:22:58+08:00\" level=fatal msg=\"validate service connection: validate CRI v1 runtime API for endpoint \\\"unix:///run/containerd/containerd.sock\\\": rpc error: code = Unavailable desc = connection error: desc = \\\"transport: Error while dialing: dial unix /run/containerd/containerd.sock: connect: connection refused\\\"\"\n, error: exit status 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T20:22:56.9757573+08:00","updatedAt":"2026-01-08T20:22:58.7408421+08:00"},{"id":"1767874976294758600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T20:22:56.2947586+08:00","updatedAt":"2026-01-08T20:22:56.948825+08:00"},{"id":"1767874092407049700","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 20:08:13.066948  216492 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:08:13.187378  216510 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 20:08:13.066948  216492 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 20:08:13.187378  216510 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T20:08:12.4070497+08:00","updatedAt":"2026-01-08T20:08:13.1556761+08:00"},{"id":"1767874091712927200","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T20:08:11.7129272+08:00","updatedAt":"2026-01-08T20:08:12.3848264+08:00"},{"id":"1767873704661249500","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 20:01:45.322118  213995 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 20:01:45.440278  214014 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\nW0108 20:01:45.322118  213995 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 20:01:45.440278  214014 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T20:01:44.6612495+08:00","updatedAt":"2026-01-08T20:01:45.3529225+08:00"},{"id":"1767873703998333600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T20:01:43.9983336+08:00","updatedAt":"2026-01-08T20:01:44.6477327+08:00"},{"id":"1767873283360211200","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 19:54:44.004656  211324 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 19:54:44.127525  211342 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\nW0108 19:54:44.004656  211324 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 19:54:44.127525  211342 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T19:54:43.3602112+08:00","updatedAt":"2026-01-08T19:54:44.1006664+08:00"},{"id":"1767873282664124200","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T19:54:42.6641242+08:00","updatedAt":"2026-01-08T19:54:43.3435796+08:00"},{"id":"1767872679871338000","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 19:44:40.500157  207581 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 19:44:40.622666  207600 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\nW0108 19:44:40.500157  207581 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 19:44:40.622666  207600 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T19:44:39.871338+08:00","updatedAt":"2026-01-08T19:44:40.6212969+08:00"},{"id":"1767872671567793000","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T19:44:31.567793+08:00","updatedAt":"2026-01-08T19:44:39.850792+08:00"},{"id":"1767871688133064600","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 19:28:08.757727  201453 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 19:28:08.879679  201474 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\nW0108 19:28:08.757727  201453 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 19:28:08.879679  201474 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T19:28:08.1330646+08:00","updatedAt":"2026-01-08T19:28:08.8978873+08:00"},{"id":"1767871679306183900","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T19:27:59.3061839+08:00","updatedAt":"2026-01-08T19:28:08.1227058+08:00"},{"id":"1767871378798973000","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 19:22:59.414172  199394 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 19:22:59.537931  199412 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 19:22:59.414172  199394 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 19:22:59.537931  199412 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T19:22:58.798973+08:00","updatedAt":"2026-01-08T19:22:59.5582292+08:00"},{"id":"1767871364324781900","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T19:22:44.3247819+08:00","updatedAt":"2026-01-08T19:22:58.7764904+08:00"},{"id":"1767870493855665500","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 19:08:14.463112  193914 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 19:08:14.584480  193932 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 19:08:14.463112  193914 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 19:08:14.584480  193932 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T19:08:13.8556655+08:00","updatedAt":"2026-01-08T19:08:14.6241939+08:00"},{"id":"1767870479478358000","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T19:07:59.478358+08:00","updatedAt":"2026-01-08T19:08:13.7946675+08:00"},{"id":"1767869449672068500","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:50:50.254286  187477 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 18:50:50.376570  187502 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\nW0108 18:50:50.254286  187477 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 18:50:50.376570  187502 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:50:49.6720685+08:00","updatedAt":"2026-01-08T18:50:50.4308111+08:00"},{"id":"1767869437825623300","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:50:37.8256233+08:00","updatedAt":"2026-01-08T18:50:49.6596129+08:00"},{"id":"1767869323725983400","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:48:44.307644  186505 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 18:48:44.434801  186524 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\nW0108 18:48:44.307644  186505 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 18:48:44.434801  186524 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:48:43.7259834+08:00","updatedAt":"2026-01-08T18:48:44.4941719+08:00"},{"id":"1767869317349327200","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:48:37.3493272+08:00","updatedAt":"2026-01-08T18:48:43.7048849+08:00"},{"id":"1767868836395848600","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:40:36.946035  183387 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 18:40:37.065008  183405 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: [preflight] Running pre-flight checks\nW0108 18:40:36.946035  183387 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 18:40:37.065008  183405 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:40:36.3958486+08:00","updatedAt":"2026-01-08T18:40:37.1420747+08:00"},{"id":"1767868828484235600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:40:28.4842356+08:00","updatedAt":"2026-01-08T18:40:36.3832454+08:00"},{"id":"1767868540000419700","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: # 重置集群，清理旧配置\nkubeadm reset --force\nrm -rf ~/.kube\n\ncat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:35:40.549063  181396 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\nW0108 18:35:40.652013  181413 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 18:35:40.549063  181396 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\nW0108 18:35:40.652013  181413 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:35:40.0004197+08:00","updatedAt":"2026-01-08T18:35:40.7162509+08:00"},{"id":"1767868533126412200","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:35:33.1264122+08:00","updatedAt":"2026-01-08T18:35:39.9793954+08:00"},{"id":"1767868156166102400","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:29:16.730540  178489 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 18:29:16.730540  178489 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:29:16.1661024+08:00","updatedAt":"2026-01-08T18:29:16.8082408+08:00"},{"id":"1767868147650588900","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:29:07.6505889+08:00","updatedAt":"2026-01-08T18:29:16.1545135+08:00"},{"id":"1767867567136053500","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 18:19:27.670578  174148 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 18:19:27.670578  174148 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T18:19:27.1360535+08:00","updatedAt":"2026-01-08T18:19:27.7500355+08:00"},{"id":"1767867557888009500","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T18:19:17.8880095+08:00","updatedAt":"2026-01-08T18:19:27.109913+08:00"},{"id":"1767866086142201600","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:54:46.657807  163529 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:54:46.657807  163529 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:54:46.1422016+08:00","updatedAt":"2026-01-08T17:54:46.7616676+08:00"},{"id":"1767866079614198500","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:54:39.6141985+08:00","updatedAt":"2026-01-08T17:54:46.1306999+08:00"},{"id":"1767865525124133200","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:45:25.623971  159383 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:45:25.623971  159383 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:45:25.1241332+08:00","updatedAt":"2026-01-08T17:45:25.7471158+08:00"},{"id":"1767865516493008700","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:45:16.4930087+08:00","updatedAt":"2026-01-08T17:45:25.1025874+08:00"},{"id":"1767864767596044300","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:32:48.098218  153850 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:32:48.098218  153850 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:32:47.5960443+08:00","updatedAt":"2026-01-08T17:32:48.2380683+08:00"},{"id":"1767864758399661100","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:32:38.3996611+08:00","updatedAt":"2026-01-08T17:32:47.5731494+08:00"},{"id":"1767864483309744400","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:28:03.801268  151649 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:28:03.801268  151649 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:28:03.3097444+08:00","updatedAt":"2026-01-08T17:28:03.9436222+08:00"},{"id":"1767864474834024900","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:27:54.8340249+08:00","updatedAt":"2026-01-08T17:28:03.2878491+08:00"},{"id":"1767864143527961800","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:22:23.974949  149043 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:22:23.974949  149043 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n[preflight] Running pre-flight checks\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:22:23.5279618+08:00","updatedAt":"2026-01-08T17:22:24.1236545+08:00"},{"id":"1767864133364864800","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:22:13.3648648+08:00","updatedAt":"2026-01-08T17:22:23.5135843+08:00"},{"id":"1767863079770096100","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 17:04:40.233609  141362 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 17:04:40.233609  141362 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T17:04:39.7700961+08:00","updatedAt":"2026-01-08T17:04:40.4146927+08:00"},{"id":"1767863068738508000","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T17:04:28.738508+08:00","updatedAt":"2026-01-08T17:04:39.7566282+08:00"},{"id":"1767862538063005300","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.31.206\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /run/containerd/containerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.30.0\nnetworking:\n  podSubnet: 192.168.0.0/16\n  serviceSubnet: 10.96.0.0/12\n  dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: [init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\nStderr: W0108 16:55:38.510116  137328 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: W0108 16:55:38.510116  137328 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme \"unix\" to the \"criSocket\" with value \"/run/containerd/containerd.sock\". Please update your configuration!\n[init] Using Kubernetes version: v1.30.0\n[preflight] Running pre-flight checks\n\t[WARNING KubernetesVersion]: Kubernetes version is greater than kubeadm version. Please consider to upgrade kubeadm. Kubernetes version: 1.30.0. Kubeadm version: 1.28.x\n\t[WARNING Hostname]: hostname \"master\" could not be reached\n\t[WARNING Hostname]: hostname \"master\": lookup master on 192.168.31.1:53: no such host\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T16:55:38.0630053+08:00","updatedAt":"2026-01-08T16:55:38.7065149+08:00"},{"id":"1767862530829793400","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T16:55:30.8297934+08:00","updatedAt":"2026-01-08T16:55:38.0520281+08:00"},{"id":"1767862369856068200","nodeId":"20260107140322","nodeName":"test","operation":"InitMaster","command":"初始化Master节点","output":"初始化失败: command failed with exit code 1: cat \u003e /tmp/kubeadm-config.yaml \u003c\u003c 'EOF'\napiVersion: \nkind: \ninitConfiguration:\n  localAPIEndpoint:\n    advertiseAddress: 192.168.31.206\n    bindPort: 6443\n  nodeRegistration:\n    criSocket: /run/containerd/containerd.sock\nclusterConfiguration:\n  kubernetesVersion: v1.30.0\n  networking:\n    podSubnet: 192.168.0.0/16\n    serviceSubnet: 10.96.0.0/12\n    dnsDomain: cluster.local\nEOF\n\n# 初始化master节点\nkubeadm init --config /tmp/kubeadm-config.yaml\n\n# 配置kubectl\nmkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n\nStdout: \nStderr: invalid configuration for GroupVersionKind /, Kind=: kind and apiVersion is mandatory information that must be specified\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n\n输出: invalid configuration for GroupVersionKind /, Kind=: kind and apiVersion is mandatory information that must be specified\nTo see the stack trace of this error execute with --v=5 or higher\ncp: cannot stat '/etc/kubernetes/admin.conf': No such file or directory\nchown: cannot access '/root/.kube/config': No such file or directory\n","status":"failed","createdAt":"2026-01-08T16:52:49.8560682+08:00","updatedAt":"2026-01-08T16:52:50.2856131+08:00"},{"id":"1767862298964989700","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装成功","status":"success","createdAt":"2026-01-08T16:51:38.9649897+08:00","updatedAt":"2026-01-08T16:52:49.8351221+08:00"},{"id":"1767862144183839100","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 添加Kubernetes仓库\nsudo cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key\nexclude=kubelet kubeadm kubectl\nEOF\n\n# 更新仓库缓存\nsudo dnf makecache\n# 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                       12 kB/s | 1.7 kB     00:00    \ncreated by dnf config-manager from https://pack 4.2 kB/s | 1.4 kB     00:00    \ncreated by dnf config-manager from https://pack 3.8 kB/s | 1.4 kB     00:00    \n\nStderr: Errors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nErrors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:49:04.1838391+08:00","updatedAt":"2026-01-08T16:49:06.7681917+08:00"},{"id":"1767862025467239300","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 添加Kubernetes仓库\nsudo cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key\nexclude=kubelet kubeadm kubectl\nEOF\n\n# 更新仓库缓存\nsudo dnf makecache\n# 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      1.9 kB/s | 1.7 kB     00:00    \ncreated by dnf config-manager from https://pack 3.7 kB/s | 1.4 kB     00:00    \ncreated by dnf config-manager from https://pack 491  B/s | 1.4 kB     00:02    \n\nStderr: Errors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nErrors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:47:05.4672393+08:00","updatedAt":"2026-01-08T16:47:11.5400615+08:00"},{"id":"1767861994373958500","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 添加Kubernetes仓库\nsudo cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key\nexclude=kubelet kubeadm kubectl\nEOF\n\n# 更新仓库缓存\nsudo dnf makecache\n# 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                       31 kB/s | 1.7 kB     00:00    \ncreated by dnf config-manager from https://pack 3.9 kB/s | 1.4 kB     00:00    \ncreated by dnf config-manager from https://pack 3.8 kB/s | 1.4 kB     00:00    \n\nStderr: Errors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nErrors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:46:34.3739585+08:00","updatedAt":"2026-01-08T16:46:37.134203+08:00"},{"id":"1767861903832893100","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 添加Kubernetes仓库\nsudo cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key\nexclude=kubelet kubeadm kubectl\nEOF\n\n# 更新仓库缓存\nsudo dnf makecache\n# 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                       46 kB/s |  25 kB     00:00    \ncreated by dnf config-manager from https://pack 3.6 kB/s | 1.4 kB     00:00    \ncreated by dnf config-manager from https://pack 2.0 kB/s | 1.4 kB     00:00    \n\nStderr: Errors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nErrors during downloading metadata for repository 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64':\n  - Status code: 404 for https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/repomd.xml (IP: 28.0.3.4)\nError: Failed to download metadata for repo 'packages.cloud.google.com_yum_repos_kubernetes-el7-x86_64': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:45:03.8328931+08:00","updatedAt":"2026-01-08T16:45:07.1788263+08:00"},{"id":"1767861429466632700","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:14    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:37:09.4666327+08:00","updatedAt":"2026-01-08T16:37:24.7034879+08:00"},{"id":"1767861101186954900","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:15    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:31:41.1869549+08:00","updatedAt":"2026-01-08T16:31:57.4321502+08:00"},{"id":"1767860907962559600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:15    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:28:27.9625596+08:00","updatedAt":"2026-01-08T16:28:44.5903497+08:00"},{"id":"1767860865511534400","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:14    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:27:45.5115344+08:00","updatedAt":"2026-01-08T16:28:01.0341542+08:00"},{"id":"1767860586155405600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:14    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:23:06.1554056+08:00","updatedAt":"2026-01-08T16:23:21.4238329+08:00"},{"id":"1767860174354286200","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:15    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:16:14.3542862+08:00","updatedAt":"2026-01-08T16:16:30.9665935+08:00"},{"id":"1767859510852166400","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: # 安装Kubernetes组件\nsudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n# 启动kubelet\nsudo systemctl enable --now kubelet\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:16    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:05:10.8521664+08:00","updatedAt":"2026-01-08T16:05:28.1032533+08:00"},{"id":"1767859232237853600","nodeId":"20260107140322","nodeName":"test","operation":"InstallKubernetesComponents","command":"安装Kubernetes组件，版本: v1.30.0","output":"安装失败: command failed with exit code 1: \n\t\t\tyum install -y yum-utils\n\t\t\tyum-config-manager --add-repo https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\n\t\t\tyum install -y kubelet kubeadm kubectl\n\t\t\tsystemctl enable --now kubelet\n\t\t\t\nStdout: Kubernetes                                      0.0  B/s |   0  B     00:14    \nAdding repo from: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nKubernetes                                      0.0  B/s |   0  B     00:16    \n\nStderr: Errors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nErrors during downloading metadata for repository 'kubernetes':\n  - Curl error (35): SSL connect error for https://prod-cdn.packages.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml [TLS connect error: error:00000000:lib(0)::reason(0)]\nError: Failed to download metadata for repo 'kubernetes': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried\nFailed to enable unit: Unit kubelet.service does not exist\n","status":"failed","createdAt":"2026-01-08T16:00:32.2378536+08:00","updatedAt":"2026-01-08T16:01:04.4242575+08:00"}]}
